


The model is composed of 3 models : 
    - A generator 
    - A discriminator 
    - A feature extractor

The generator is composed of 6 sequential UNET, each take as input a
[512,512,1] tensor and output a [512,512,1] tensor. 
The input tensor is the orginal image with artefact in it and the final output of
the generator is supposed to be the image without artefact.
Each UNET has the same architecture : 
    8 Down block of : 
        - Conv2D 
        - BatchNormalization
        - LeakyReLU
    8 Upblock of :
        - Conv2DTranspose 
        - Batch Norm 
        - Relu 
Add the end of the sequence of UNET we add last Conv2DTranspose with kernel of size 1 and sigmoid activation

The discriminator follow a modified PatchGAN architecture that is to say 4 block of :  
    - Conv2D
    - BatchNormalization
    - LeakyReLU

The feature extractor was trained as a classifier for the amount of metal in the image (no metal, low amout of metal and high amount of metal) 
during the training of the global model we freeze it's weight, and use only the feature extracted from it's layer to calculate the style loss and the content loss
It's follow the VGG19 architecture
